<html>
    <body></body>
    <script type="text/javascript">"use strict";

// stuff gets swapped into here
const common_code     = `
#define SOURCE 1

#define VORONOI_EXPONENT 2.0
#define VORONOI_RANDOMNESS 1.0
#define VORONOI_ANGLE 3.14159/4.
#define VORONOI_UV_SCALE 10.

const ivec2 MOUSE_DOWN_ADDR = ivec2(2);
const ivec2 DRAW_ADDR       = ivec2(3);
const ivec2 M2_POS_ADDR = ivec2(4);
const ivec2 M1_POS_ADDR = ivec2(5);
const ivec2 M0_POS_ADDR = ivec2(6);

// per IQ: https://www.iquilezles.org/www/articles/distfunctions2d/distfunctions2d.htm
float segmentDist(vec2 p, vec2 a, vec2 b) {
    vec2 pa = p-a, ba = b-a;
    float h = clamp( dot(pa,ba)/dot(ba,ba), 0.0, 1.0 );
    return length( pa - ba*h );
}

// https://thebookofshaders.com/12/
vec2 random2f( vec2 p ) {
    return fract(
        sin(
            vec2(
                dot(p,vec2(127.1,311.7)),
                dot(p,vec2(269.5,183.3)))
        )*(43758.5453)
    );
}

float veronoi_metric( in vec2 r, float exponent, float angle ) {
    // manhattan
    //return dot(abs(r), vec2(1.));
    // euclidean
    //return dot(r,r);
    return dot(pow(abs(r),vec2(exponent)), 0.01+abs(vec2(cos(angle), sin(angle))));
}


vec4 voronoi_f1_colors( in vec2 x, float randomness, float power, float angle )
{
    vec2 p = floor( x );
    vec2  f = fract( x );

    float res = 8.0;
    vec3 res_col = vec3(0.);
    for( int j=-1; j<=1; j++ )
    for( int i=-1; i<=1; i++ )
    {
        vec2 b = vec2( i, j );
        vec2 point = random2f( vec2(p + b) );
        vec2  r = vec2( b ) - f + randomness*point;
        float d = veronoi_metric( r, power, angle);
        vec3 col = vec3(point,1.);

        res_col = (d < res) ? col : res_col;
        res = min( res, d );
    }
    return vec4(res_col, sqrt( res ));
}

float divergence_calculation(vec2 va, vec2 vb, vec2 vc, vec2 vd, vec2 ve, vec2 vf, vec2 vg, vec2 vh, vec2 vi) {

    float divergence = 
    dot(normalize(va), -0.707*vec2(-1,-1)) +
    dot(normalize(vb), -vec2(-1, 0)) +
    dot(normalize(vc), -0.707*vec2(-1, 1)) +
    dot(normalize(vd), -vec2( 0,-1)) +
    dot(normalize(ve), -vec2( 0, 0)) +
    dot(normalize(vf), -vec2( 0, 1)) +
    dot(normalize(vg), -0.707*vec2( 1,-1)) +
    dot(normalize(vh), -vec2( 1, 0)) +
    dot(normalize(vi), -0.707*vec2( 1, 1));
    
    return (divergence) / 1.;
}


vec2 get_mouse_perturbation_calcuation(in vec2 fragCoord, bool draw, vec2 m2, vec2 m1, vec2 m0) {
    

    // use some distance fields to calculate brush size
    float dist1 = segmentDist(fragCoord, m2, m1);
    float dist2 = segmentDist(fragCoord, m1, m0);
    float dist = min(dist1,dist2);
    vec2 mouse_v = m2-m1;
    bool brush = dist < 15.;
    bool moving = length(mouse_v) > 0.;
    
    // update the color - in the future this will be an IMPULSE
    float strength = (1./(dist+1.));    
    vec2 perturb = (draw && brush && moving) ? strength*mouse_v : vec2(0.);
    
    return perturb;
}

`
const external_code = `





void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
    fragColor = texture(iChannel2, fragCoord / iResolution.xy);
 }`;
const external_code_A = `/*
Flow Map
*/



const float fade = 0.9;
const float eps = 1e-3;



vec2 sign_preserving_max(vec2 a, vec2 b) {

    float x1 = a.x;
    float y1 = a.y;
    float x2 = b.x;
    float y2 = b.y;
    
    float x = max(abs(x1),abs(x2));
    x *= (x == abs(x1)) ? sign(x1) : sign(x2);
    
    float y = max(abs(y1),abs(y2));
    y *= (y == abs(y1)) ? sign(y1) : sign(y2);
    
    return vec2(x,y);
}

vec2 get_mouse_perturbation(in vec2 fragCoord) {
    // read mouse variables
    bool draw      = texelFetch(iChannel1, DRAW_ADDR, 0).x > 0.;
    vec2 m2 = texelFetch(iChannel1, M2_POS_ADDR, 0).xy;
    vec2 m1 = texelFetch(iChannel1, M1_POS_ADDR, 0).xy;
    vec2 m0 = texelFetch(iChannel1, M0_POS_ADDR, 0).xy;

    return get_mouse_perturbation_calcuation(fragCoord, draw, m2, m1, m0);
}

float weight_closeness(vec2 x) {
    return (1. + eps) / (eps+ length(x) );
}

vec2 getAdvectedV(in vec2 fragCoord) {
    
    // sample the velocities around this point
    vec2 va = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vb = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vc = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vd = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 ve = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vf = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vg = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vh = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vi = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 1)) % ivec2(iResolution.xy), 0).xy;

    // where the neighboring grid positions end up after the timestep
    vec2 pa = (va + vec2(-1.,-1.));
    vec2 pb = (vb + vec2(-1,  0.));
    vec2 pc = (vc + vec2(-1., 1.));
    vec2 pd = (vd + vec2( 0.,-1.));
    vec2 pe = (ve + vec2( 0., 0.));
    vec2 pf = (vf + vec2( 0., 1.));
    vec2 pg = (vg + vec2( 1.,-1.));
    vec2 ph = (vh + vec2( 1., 0.));
    vec2 pi = (vi + vec2( 1., 1.));
    
    /*
    float wa = max(eps,1.-length(pa));
    float wb = max(eps,1.-length(pb));
    float wc = max(eps,1.-length(pc));
    float wd = max(eps,1.-length(pd));
    float we = max(eps,1.-length(pe));
    float wf = max(eps,1.-length(pf));
    float wg = max(eps,1.-length(pg));
    float wh = max(eps,1.-length(ph));
    float wi = max(eps,1.-length(pi));
    */
    float wa = weight_closeness(pa);
    float wb = weight_closeness(pb);
    float wc = weight_closeness(pc);
    float wd = weight_closeness(pd);
    float we = weight_closeness(pe);
    float wf = weight_closeness(pf);
    float wg = weight_closeness(pg);
    float wh = weight_closeness(ph);
    float wi = weight_closeness(pi);
    
    
    float denom = max(eps,wa+wb+wc+wd+we+wf+wg+wh+wi);
    return ((wa*va + wb*vb + wc*vc + wd*vd + we*ve + wf*vf + wg*vg + wh*vh + wi*vi))/ denom;
    
    //return (va+vb+vc+vd+ve+vf+vg+vh+vi)/9.;
}

float getDivergence(in vec2 fragCoord) {
    
    // sample the velocities around this point
    vec2 va = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vb = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vc = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vd = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 ve = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vf = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vg = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vh = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vi = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 1)) % ivec2(iResolution.xy), 0).xy;

    return divergence_calculation(va,vb,vc,vd,ve,vf,vg,vh,vi);
    
    //return (va+vb+vc+vd+ve+vf+vg+vh+vi)/9.;
}

vec2 bound(vec2 x) {
    return length(x) > 1. ? normalize(x) : x;
}

vec2 get_random_v(in vec2 fragCoord) {
    return voronoi_f1_colors( fragCoord, VORONOI_RANDOMNESS, VORONOI_EXPONENT, VORONOI_ANGLE).xy - 0.5;
}

vec2 camGradient(in vec2 fragCoord) {
    vec2 uv = fragCoord / iResolution.xy;
    vec2 e = vec2(0.5/iResolution.x, 0.);
    #if SOURCE == 0
    vec2 grad = vec2(length(texture(iChannel3, uv + e.xy).xyz) - length(texture(iChannel3, uv - e.xy).xyz),
                length(texture(iChannel3, uv + e.yx).xyz) - length(texture(iChannel3, uv - e.yx).xyz));
    #else
    vec2 grad = vec2(length(voronoi_f1_colors( uv + e.xy, VORONOI_RANDOMNESS, VORONOI_EXPONENT, VORONOI_ANGLE ).xyz) -
    length(voronoi_f1_colors( uv - e.xy, VORONOI_RANDOMNESS, VORONOI_EXPONENT, VORONOI_ANGLE ).xyz),
    length(voronoi_f1_colors( uv + e.yx, VORONOI_RANDOMNESS, VORONOI_EXPONENT, VORONOI_ANGLE ).xyz) -
    length(voronoi_f1_colors( uv - e.yx, VORONOI_RANDOMNESS, VORONOI_EXPONENT, VORONOI_ANGLE ).xyz));
    //vec2 grad = vec2(length(texture(iChannel3, uv + e.xy).xyz) - length(texture(iChannel3, uv - e.xy).xyz),
    //            length(texture(iChannel3, uv + e.yx).xyz) - length(texture(iChannel3, uv - e.yx).xyz));
    #endif
    return grad;
}

void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
    vec2 random_v = get_random_v(VORONOI_UV_SCALE*fragCoord/iResolution.xy); //texture(iChannel2,0.1*fragCoord/iResolution.xy).xy-vec2(0.5);

    if (1 == 0) {
        fragColor = vec4(random_v,1.,1.);
    }
    else {
    
    // TRAIT: -1. * 
    vec2 cam_grad = camGradient(fragCoord);

    // advection step
    vec2 v = getAdvectedV(fragCoord);
    
    float d = getDivergence(fragCoord);
    
    //v = v * (1. + length(cam_grad));

    vec2 perturb = clamp(get_mouse_perturbation(fragCoord), -1.,1.);
    
    // TRAIT: oscillate?
    //v = v + perturb + clamp(sin(2.*iTime),0.,1.) * cam_grad;
    
    v = v + perturb + 0.5 * cam_grad;
    
    v = bound(v);
    
    fragColor = vec4(v,0.,1.);
    }
}`;
const external_code_B = `/*
Mouse tracking / interactivity
*/




void mainImage( out vec4 fragColor, in vec2 fragCoord )
{    
    vec4 m2_mouse  = texelFetch(iChannel1, M2_POS_ADDR, 0);
    vec4 m1_mouse  = texelFetch(iChannel1, M1_POS_ADDR, 0);
    vec4 m0_mouse  = texelFetch(iChannel1, M0_POS_ADDR, 0);

    
    bool draw = (iMouse.z > 0.) && (m2_mouse.z > 0.) && (m1_mouse.z > 0.);

    if (ivec2(fragCoord) == M2_POS_ADDR) {
        //vec2 prevMouse = texelFetch(iChannel1, MOUSE_POS_ADDR, 0).xy;
        fragColor = vec4(iMouse.xyz, 0.);
    }
    
    if (ivec2(fragCoord) == M1_POS_ADDR) {
        fragColor = m2_mouse;
    }
    
    if (ivec2(fragCoord) == M0_POS_ADDR) {
        fragColor = m1_mouse;
    }

    
    if (ivec2(fragCoord) == DRAW_ADDR) {
        fragColor = draw ? vec4(1.) : vec4(0.);
    }
}`;
const external_code_C = `


vec2 get_mouse_perturbation(in vec2 fragCoord) {
    // read mouse variables
    bool draw      = texelFetch(iChannel1, DRAW_ADDR, 0).x > 0.;
    vec2 m2 = texelFetch(iChannel1, M2_POS_ADDR, 0).xy;
    vec2 m1 = texelFetch(iChannel1, M1_POS_ADDR, 0).xy;
    vec2 m0 = texelFetch(iChannel1, M0_POS_ADDR, 0).xy;

    return get_mouse_perturbation_calcuation(fragCoord, draw, m2, m1, m0);
}

float getDivergence(in vec2 fragCoord) {
    
    // sample the velocities around this point
    vec2 va = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vb = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vc = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vd = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 ve = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vf = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vg = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vh = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vi = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 1)) % ivec2(iResolution.xy), 0).xy;

    return divergence_calculation(va,vb,vc,vd,ve,vf,vg,vh,vi);
    
    //return (va+vb+vc+vd+ve+vf+vg+vh+vi)/9.;
}

vec2 get_v(in vec2 fragCoord) {
    return texture(iChannel0, fragCoord / iResolution.xy).xy;
}

float shade(vec2 fragCoord) {
    float a = length(get_v(fragCoord+ vec2(1,0))); //voronoi_f1_colors( 10.* (fragCoord + vec2(0,1)) / iResolution.xy, 1.0, 2.0, 3.14159/4.).w;
    float b = length(get_v(fragCoord + vec2(-1,0)));//voronoi_f1_colors( 10.* (fragCoord + vec2(0,-1)) / iResolution.xy, 1.0, 2.0, 3.14159/4.).w;
    float c = length(get_v(fragCoord + vec2(0,1)));//voronoi_f1_colors( 10.* (fragCoord + vec2(1,0)) / iResolution.xy, 1.0, 2.0, 3.14159/4.).w;
    float d = length(get_v(fragCoord + vec2(0,-1)));//voronoi_f1_colors( 10.* (fragCoord + vec2(-1,0)) / iResolution.xy, 1.0, 2.0, 3.14159/4.).w;
    vec2 grad = normalize(vec2((a-b)/2., (c-d)/2.));
    vec2 light = vec2(cos(iTime),sin(iTime));
    return 0.5 + 0.5 *dot(grad,light);
    //return 5.*a;
}


// from https://www.shadertoy.com/view/MsjXRt
// todo: my own implementation
vec3 HueShift (in vec3 Color, in float Shift)
{
    vec3 P = vec3(0.55735)*dot(vec3(0.55735),Color);
    
    vec3 U = Color-P;
    
    vec3 V = cross(vec3(0.55735),U);    

    Color = U*cos(Shift*6.2832) + V*sin(Shift*6.2832) + P;
    
    return Color;
}


void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
    vec2 uv = fragCoord / iResolution.xy;

    // sample flow map
    vec2 flow = texture(iChannel0, (fragCoord)/iResolution.xy).xy;
    
    // get some vector quantities
    float d = getDivergence(fragCoord);
    float divergence = clamp(-d, 0.,1.);
    float convergence = clamp(d, 0., 1.);

    // use the flowmap to offset sampling into the previous frame
    vec4 prev = texture(iChannel2, vec2(fragCoord - flow) / iResolution.xy);
    
    // TRAITS: 0.99, 0.999
    prev*=0.99;
    
    
    #if SOURCE == 0
    vec4 colors = texture(iChannel3, fragCoord / iResolution.xy);
    #else
    vec4 colors =  voronoi_f1_colors( VORONOI_UV_SCALE * fragCoord / iResolution.xy, VORONOI_RANDOMNESS, VORONOI_EXPONENT, VORONOI_ANGLE);    
    #endif

    // TRAIT: 1.- is a trait
    //

    vec3 result = clamp(0.15*divergence * colors.xyz + (1.-0.15*divergence) * prev.xyz, 0., 1.);
    
    float mouse_movement = length(get_mouse_perturbation(fragCoord));
    
    //result = HueShift(result, length(result)*30.);
    
    result = (1.+0.01*length(flow))*HueShift(clamp(result,0.,1.), 0.005*length(flow));

    //vec3 result = shade(fragCoord) * mix(prev.xyz, colors.xyz, divergence);
    fragColor = vec4(result,colors.w);// vec4(divergence,divergence,divergence,1.);
    //}
}`;

// Some of this code is based off of: https://codepen.io/jbltx/pen/eYZwEja

const app = {

    status : null, /* null (uninitialized), 'ready', 'animate', 'capture' */

    canvas: null, /* The canvas element */
    gl: null, /* Webgl2 context for the canvas */
    mode: null, /* capture or animate */
    capture: null, /* base64 capture */

    // mouse tracking
    mouseX: 0.0,
    mouseY: 0.0,
    mouseZ: 0.0,

    /* not sure about this one */
    vertexArray: null,

    /* programs */
    program: null,
    bufferAProgram: null,
    bufferBProgram: null,
    bufferCProgram: null,

    // frame buffers
    framebufferA : null,
    framebufferB : null,
    framebufferC : null,

    // textures
    textureA: null,
    textureB: null,
    textureC: null,

    /* Time stuff */
    frame: 0,
    time: 0,
    lastTime: 0
};


function init() {

  createCanvasIfNotExists();
  createWebGLContextIfNotExists();
  createVertexArray();
  createPrograms();
  createFrameBuffers();
  createNewTextures();

  app.status = "ready";
}

function render(now) {

  setTime(now);

  drawBuffer(app.bufferAProgram, app.framebufferA, app.textureA);
  drawBuffer(app.bufferBProgram, app.framebufferB, app.textureB);
  drawBuffer(app.bufferCProgram, app.framebufferC, app.textureC);
  drawShader(app.program);

  app.frame += 1;

  // if render was called in "capture" mode, dump the canvas to app.capture and don't request another frame
  if (app.mode == "capture") {
    app.capture = app.canvas.toDataURL('image/png', 1).substring(22);
  }
  // if render was called in "animate" mode, request another frame
  else if (app.mode == "animate") {
     requestAnimationFrame(render);
  }

}


function capture(time, x, y) {
  resizeCanvas(x,y);
  app.mode = "capture";
  render(time);
}

function animate() {
  app.mode = "animate";
  requestAnimationFrame(render);
}

function stop() {
  app.mode = "capture"; // todo: 'stopped' status?
}


function click_setMouseXY(e) {
    const canvas = app.canvas;
    const rect = canvas.getBoundingClientRect();
    app.mouseX = e.clientX - rect.left;
    app.mouseY = rect.height - (e.clientY - rect.top) - 1;  // bottom is 0 in WebGL
}

function touch_setMouseXY(e) {
  e.preventDefault();
  const canvas = app.canvas;
  const rect = canvas.getBoundingClientRect();
  
  // i'm reading that on android mobile the property is changedTouches
  let touch = null;
  if (e.touches) {
    touch = e.touches[0]
  }
  else if (e.changedTouches) {
    touch = e.changedTouches[0]
  }

  app.mouseX = touch.pageX - rect.left;
  app.mouseY = rect.height - (touch.pageY - rect.top) - 1;  // bottom is 0 in WebGL
}

function handle_mousedown(e) {
  e.preventDefault();
  app.mouseZ = 1.0;
}

function handle_mouseup(e) {
  e.preventDefault();
  app.mouseZ = 0.0;
}

function handle_touchstart(e) {
  e.preventDefault();
  app.mouseZ = 1.0;
}

function handle_touchend(e) {
  e.preventDefault();
  app.mouseZ = 0.0;
}

function createWebGLContextIfNotExists() {
  // lazy load the web gl context
  if (!app.gl) {
      app.gl = app.canvas.getContext("webgl2");
  }
}

// create a canvas element the size of the screen, that also automatically resizes and updates mouse positions
function createCanvasIfNotExists() {

    // lazy create the canvas
    if (!app.canvas) {
        const canvas = document.createElement('canvas');
        canvas.setAttribute("id", "canvas");
        document.body.appendChild(canvas);
        app.canvas = canvas;
    }

    // make the canvas as big as the window
    resizeCanvas(window.innerWidth, window.innerHeight);

    // and if the window ever changes sizes, resize the canvas to match it
    window.addEventListener('resize', handleResize);

    // touchmove (tablets/phones) or mousemove...
    app.canvas.addEventListener('mousemove', click_setMouseXY);
    app.canvas.addEventListener('touchmove', touch_setMouseXY);

    // touchstart/end (tablets/phones) or mouseup/down
    app.canvas.addEventListener('mousedown', handle_mousedown);
    app.canvas.addEventListener('mouseup', handle_mouseup);
    app.canvas.addEventListener('touchstart', handle_touchstart);
    app.canvas.addEventListener('touchend', handle_touchend);
}

function handleResize() {
  resizeCanvas(window.innerWidth, window.innerHeight);
}

function resizeCanvas(x,y) {

    const canvas = app.canvas;

    if (!canvas) {
      return;
    }

    const dirty = (x != canvas.width) || (y != canvas.height);

    if (dirty) {
      canvas.width = x;
      canvas.height = y;
    }
  
    // if the canvas size changes, we have to recreate our multipass textures with the new dimensions
    const initialized = !!app.mode;
    const valid = (canvas.width >= 0 && canvas.height >= 0);

    if (dirty && valid && initialized) {
      createNewTextures();
    }
}


function createNewTextures() {

  const gl = app.gl;

  if (app.textureA) {
    gl.deleteTexture(app.textureA);
  }
  app.textureA = createTexture();   
  
  if (app.textureB) {
    gl.deleteTexture(app.textureB);
  }
  app.textureB = createTexture(); 

  if (app.textureB) {
    gl.deleteTexture(app.textureC);
  }
  app.textureC = createTexture();   

}

function createVertexArray() {
  const gl = app.gl;
  app.vertexArray = gl.createVertexArray();
  gl.bindVertexArray(app.vertexArray);
  gl.bindVertexArray(null);
}


function createPrograms() {
  app.bufferAProgram = createShaderProgram(getCommonShaderCode() + getBufferFragmentShaderCode("A"));
  app.bufferBProgram = createShaderProgram(getCommonShaderCode() + getBufferFragmentShaderCode("B"));
  app.bufferCProgram = createShaderProgram(getCommonShaderCode() + getBufferFragmentShaderCode("C"));
  app.program        = createShaderProgram(getCommonShaderCode() + getFragmentShaderCode());  
}

function createFrameBuffers() {
  const gl = app.gl;
  app.framebufferA = gl.createFramebuffer();
  app.framebufferB = gl.createFramebuffer();    
  app.framebufferC = gl.createFramebuffer();  
}

function createShaderProgram(fragmentShaderCode) {
  
  const gl = app.gl;

  const program = gl.createProgram();
  const vertexShader = createShader(getVertexShaderCode(), gl.VERTEX_SHADER);
  const fragmentShader = createShader(fragmentShaderCode, gl.FRAGMENT_SHADER);
  gl.attachShader(program, vertexShader);
  gl.attachShader(program, fragmentShader);
  gl.linkProgram(program);
  var success = gl.getProgramParameter(program, gl.LINK_STATUS);
  if (!success) {
      throw ("program filed to link:" + gl.getProgramInfoLog (program));
  }    
  return program;
}

function createShader(shaderCode, shaderType) {
  
  const gl = app.gl;

  var shader = gl.createShader(shaderType);
  gl.shaderSource(shader, shaderCode);
  gl.compileShader(shader);

  var message = gl.getShaderInfoLog(shader);
  if (message.length > 0) {
    /* message may be an error or a warning */
    //throw message; 
    throw "could not compile shader:" + gl.getShaderInfoLog(shader);
  }

  return shader;
}

function createTexture() 
{
    const gl = app.gl;
    const w = gl.canvas.width;
    const h = gl.canvas.height;

    //var ext = gl.getExtension('OES_texture_float');
    //ext = gl.getExtension("EXT_color_buffer_float");
    
    const texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, w, h, 
                                   0, gl.RGBA, gl.UNSIGNED_BYTE, null);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.bindTexture(gl.TEXTURE_2D, null);
    return texture;
}

function drawShader(program) {

  const gl = app.gl;
  const time = app.time;

  gl.bindFramebuffer(gl.FRAMEBUFFER, null);

  // TODO: remove these lines? 
  gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
  //gl.clearColor(0, 0, 0, 0);
  //gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

  gl.useProgram(program);

  gl.uniform1f(gl.getUniformLocation(program, "iTime"), time);
  gl.uniform3f(gl.getUniformLocation(program, "iMouse"), app.mouseX, app.mouseY, app.mouseZ);
  gl.uniform3f(gl.getUniformLocation(program, "iResolution"), gl.canvas.width, gl.canvas.height, 1.0);
  gl.uniform1i(gl.getUniformLocation(program, "iFrame"), app.frame);    

  // bind channel 0
  gl.activeTexture(gl.TEXTURE0);
  gl.bindTexture(gl.TEXTURE_2D, app.textureA);
  gl.uniform1i(gl.getUniformLocation(program, "iChannel0"), 0);

  // bind channel 1
  gl.activeTexture(gl.TEXTURE1);
  gl.bindTexture(gl.TEXTURE_2D, app.textureB);
  gl.uniform1i(gl.getUniformLocation(program, "iChannel1"), 1);

  // bind channel 2
  gl.activeTexture(gl.TEXTURE2);
  gl.bindTexture(gl.TEXTURE_2D, app.textureC);
  gl.uniform1i(gl.getUniformLocation(program, "iChannel2"), 2);

  gl.bindVertexArray(app.vertexArray);
  gl.drawArrays(gl.TRIANGLES, 0, 6);
}

function drawBuffer(program, frameBuffer, texture) {

    const gl = app.gl;
    const time = app.time;

    gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);

    // TODO: remove these lines? 
    gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
    //gl.clearColor(0, 0, 0, 0); // this line doesn't cause an error
    //gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);


    gl.useProgram(program);

    gl.uniform1f(gl.getUniformLocation(program, "iTime"), time);
    gl.uniform3f(gl.getUniformLocation(program, "iMouse"), app.mouseX, app.mouseY, app.mouseZ);
    gl.uniform3f(gl.getUniformLocation(program, "iResolution"), gl.canvas.width, gl.canvas.height, 1.0);
    gl.uniform1i(gl.getUniformLocation(program, "iFrame"), app.frame);    

    // bind channel 0
    if (texture != app.textureA) {
      gl.activeTexture(gl.TEXTURE0);
      gl.bindTexture(gl.TEXTURE_2D, app.textureA);
      gl.uniform1i(gl.getUniformLocation(program, "iChannel0"), 0);
    }


    // bind channel 1
    if (texture != app.textureB) {
      gl.activeTexture(gl.TEXTURE1);
      gl.bindTexture(gl.TEXTURE_2D, app.textureB);
      gl.uniform1i(gl.getUniformLocation(program, "iChannel1"), 1);
    }

  
    // bind channel 2
    if (texture != app.textureC) {
      gl.activeTexture(gl.TEXTURE2);
      gl.bindTexture(gl.TEXTURE_2D, app.textureC);
      gl.uniform1i(gl.getUniformLocation(program, "iChannel2"), 2);
    }

    

    gl.bindVertexArray(app.vertexArray);
    gl.drawArrays(gl.TRIANGLES, 0, 6);

    
}

function setTime(now) {
  // if render was called in "animate" mode, add the elapsed item to current time
  if (app.mode == "animate") {
    now *= 0.001;  // convert to seconds
    const elapsedTime = Math.min(now - app.lastTime, 0.1);
    app.time += elapsedTime;
    app.lastTime = now;
  }
  // if render was called in "capture" mode, the requested time ("now") is the time we want
  else if (app.mode == "capture") {
    app.time = now;
  }
}

function getVertexShaderCode() {
  const vertexPlane = `#version 300 es  
    void main()
    {
      float x = float((gl_VertexID & 1) << 2);
      float y = float((gl_VertexID & 2) << 1);
      gl_Position = vec4(x - 1.0, y - 1.0, 0, 1);
    }
  `;
  return vertexPlane;
}


function getCommonShaderCode() {

  const fs = `#version 300 es

    precision mediump float;
`

    +

    common_code;

  return fs;
}


function getBufferFragmentShaderCode(buffer) {

  const buffer_code = ({ "A": external_code_A, "B": external_code_B, "C": external_code_C })[buffer];

  const fs = `
    layout(location = 0) out vec4 myOutputColor;

    uniform sampler2D iChannel0;
    uniform sampler2D iChannel1;
    uniform sampler2D iChannel2;
    uniform sampler2D iChannel3;

    uniform vec3 iResolution;
    uniform vec3 iMouse;
    uniform float iTime;
    uniform int iFrame;
    `

    

    +

    buffer_code

    +

    `
    
    void main() {
      mainImage(myOutputColor, gl_FragCoord.xy);
    }
  `;

  return fs;

}

function getFragmentShaderCode() {
  // build the fragment shader by prepending / postpending other code
  const fs = `
    layout(location = 0) out vec4 myOutputColor;

    uniform sampler2D iChannel0;
    uniform sampler2D iChannel1;
    uniform sampler2D iChannel2; 
    uniform sampler2D iChannel3;    

    uniform vec3 iResolution;
    uniform vec3 iMouse;
    uniform float iTime;
    uniform int iFrame;
    `

    

    +

    external_code

    +

    `
    
    void main() {
      mainImage(myOutputColor, gl_FragCoord.xy);
    }
  `;

  return fs;

}



init();
animate();</script>
</html>