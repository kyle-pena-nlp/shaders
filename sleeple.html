<html>
    <body></body>
    <script type="text/javascript">"use strict";

// stuff gets swapped into here
const common_code     = `
#define VORONOI_EXPONENT 2.0
#define VORONOI_RANDOMNESS 1.0
#define VORONOI_ANGLE 3.14159/4.
#define VORONOI_UV_SCALE 10.

const ivec2 MOUSE_DOWN_ADDR = ivec2(2);
const ivec2 DRAW_ADDR       = ivec2(3);
const ivec2 M2_POS_ADDR = ivec2(4);
const ivec2 M1_POS_ADDR = ivec2(5);
const ivec2 M0_POS_ADDR = ivec2(6);

// per IQ: https://www.iquilezles.org/www/articles/distfunctions2d/distfunctions2d.htm
float segmentDist(vec2 p, vec2 a, vec2 b) {
    vec2 pa = p-a, ba = b-a;
    float h = clamp( dot(pa,ba)/dot(ba,ba), 0.0, 1.0 );
    return length( pa - ba*h );
}

// https://thebookofshaders.com/12/
vec2 random2f( vec2 p ) {
    return fract(
        sin(
            vec2(
                dot(p,vec2(127.1,311.7)),
                dot(p,vec2(269.5,183.3)))
        )*(43758.5453)
    );
}

float veronoi_metric( in vec2 r, float exponent, float angle ) {
    // manhattan
    //return dot(abs(r), vec2(1.));
    // euclidean
    //return dot(r,r);
    return dot(pow(abs(r),vec2(exponent)), 0.01+abs(vec2(cos(angle), sin(angle))));
}


vec4 voronoi_f1_colors( in vec2 x, float randomness, float power, float angle )
{
    vec2 p = floor( x );
    vec2  f = fract( x );

    float res = 8.0;
    vec3 res_col = vec3(0.);
    for( int j=-1; j<=1; j++ )
    for( int i=-1; i<=1; i++ )
    {
        vec2 b = vec2( i, j );
        vec2 point = random2f( vec2(p + b) );
        vec2  r = vec2( b ) - f + randomness*point;
        float d = veronoi_metric( r, power, angle);
        vec3 col = vec3(point,1.);

        res_col = (d < res) ? col : res_col;
        res = min( res, d );
    }
    return vec4(res_col, sqrt( res ));
}

float divergence_calculation(vec2 va, vec2 vb, vec2 vc, vec2 vd, vec2 ve, vec2 vf, vec2 vg, vec2 vh, vec2 vi) {

    float divergence = 
    dot(normalize(va), -0.707*vec2(-1,-1)) +
    dot(normalize(vb), -vec2(-1, 0)) +
    dot(normalize(vc), -0.707*vec2(-1, 1)) +
    dot(normalize(vd), -vec2( 0,-1)) +
    dot(normalize(ve), -vec2( 0, 0)) +
    dot(normalize(vf), -vec2( 0, 1)) +
    dot(normalize(vg), -0.707*vec2( 1,-1)) +
    dot(normalize(vh), -vec2( 1, 0)) +
    dot(normalize(vi), -0.707*vec2( 1, 1));
    
    return (divergence) / 1.;
}


vec2 get_mouse_perturbation_calcuation(in vec2 fragCoord, bool draw, vec2 m2, vec2 m1, vec2 m0) {
    

    // use some distance fields to calculate brush size
    float dist1 = segmentDist(fragCoord, m2, m1);
    float dist2 = segmentDist(fragCoord, m1, m0);
    float dist = min(dist1,dist2);
    vec2 mouse_v = m2-m1;
    bool brush = dist < 15.;
    bool moving = length(mouse_v) > 0.;
    
    // update the color - in the future this will be an IMPULSE
    float strength = (1./(dist+1.));    
    vec2 perturb = (draw && brush && moving) ? strength*mouse_v : vec2(0.);
    
    return perturb;
}

`
const external_code = `





void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
    fragColor = texture(iChannel2, fragCoord / iResolution.xy);
 }`;
const external_code_A = `/*
Flow Map
*/



const float fade = 0.9;
const float eps = 1e-3;



vec2 sign_preserving_max(vec2 a, vec2 b) {

    float x1 = a.x;
    float y1 = a.y;
    float x2 = b.x;
    float y2 = b.y;
    
    float x = max(abs(x1),abs(x2));
    x *= (x == abs(x1)) ? sign(x1) : sign(x2);
    
    float y = max(abs(y1),abs(y2));
    y *= (y == abs(y1)) ? sign(y1) : sign(y2);
    
    return vec2(x,y);
}

vec2 get_mouse_perturbation(in vec2 fragCoord) {
    // read mouse variables
    bool draw      = texelFetch(iChannel1, DRAW_ADDR, 0).x > 0.;
    vec2 m2 = texelFetch(iChannel1, M2_POS_ADDR, 0).xy;
    vec2 m1 = texelFetch(iChannel1, M1_POS_ADDR, 0).xy;
    vec2 m0 = texelFetch(iChannel1, M0_POS_ADDR, 0).xy;

    return get_mouse_perturbation_calcuation(fragCoord, draw, m2, m1, m0);
}

float weight_closeness(vec2 x) {
    return (1. + eps) / (eps+ length(x) );
}

vec2 getAdvectedV(in vec2 fragCoord) {
    
    // sample the velocities around this point
    vec2 va = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vb = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vc = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vd = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 ve = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vf = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vg = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vh = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vi = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 1)) % ivec2(iResolution.xy), 0).xy;

    // where the neighboring grid positions end up after the timestep
    vec2 pa = (va + vec2(-1.,-1.));
    vec2 pb = (vb + vec2(-1,  0.));
    vec2 pc = (vc + vec2(-1., 1.));
    vec2 pd = (vd + vec2( 0.,-1.));
    vec2 pe = (ve + vec2( 0., 0.));
    vec2 pf = (vf + vec2( 0., 1.));
    vec2 pg = (vg + vec2( 1.,-1.));
    vec2 ph = (vh + vec2( 1., 0.));
    vec2 pi = (vi + vec2( 1., 1.));
    
    /*
    float wa = max(eps,1.-length(pa));
    float wb = max(eps,1.-length(pb));
    float wc = max(eps,1.-length(pc));
    float wd = max(eps,1.-length(pd));
    float we = max(eps,1.-length(pe));
    float wf = max(eps,1.-length(pf));
    float wg = max(eps,1.-length(pg));
    float wh = max(eps,1.-length(ph));
    float wi = max(eps,1.-length(pi));
    */
    float wa = weight_closeness(pa);
    float wb = weight_closeness(pb);
    float wc = weight_closeness(pc);
    float wd = weight_closeness(pd);
    float we = weight_closeness(pe);
    float wf = weight_closeness(pf);
    float wg = weight_closeness(pg);
    float wh = weight_closeness(ph);
    float wi = weight_closeness(pi);
    
    
    float denom = max(eps,wa+wb+wc+wd+we+wf+wg+wh+wi);
    return ((wa*va + wb*vb + wc*vc + wd*vd + we*ve + wf*vf + wg*vg + wh*vh + wi*vi))/ denom;
    
    //return (va+vb+vc+vd+ve+vf+vg+vh+vi)/9.;
}

float getDivergence(in vec2 fragCoord) {
    
    // sample the velocities around this point
    vec2 va = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vb = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vc = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vd = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 ve = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vf = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vg = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vh = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vi = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 1)) % ivec2(iResolution.xy), 0).xy;

    return divergence_calculation(va,vb,vc,vd,ve,vf,vg,vh,vi);
    
    //return (va+vb+vc+vd+ve+vf+vg+vh+vi)/9.;
}

vec2 bound(vec2 x) {
    return length(x) > 1. ? normalize(x) : x;
}

vec2 get_random_v(in vec2 fragCoord) {
    return voronoi_f1_colors( fragCoord, VORONOI_RANDOMNESS, VORONOI_EXPONENT, VORONOI_ANGLE).xy - 0.5;
}

vec2 camGradient(in vec2 fragCoord) {
    vec2 uv = fragCoord / iResolution.xy;
    vec2 e = vec2(0.5/iResolution.x, 0.);
    vec2 grad = vec2(length(texture(iChannel3, uv + e.xy).xyz) - length(texture(iChannel3, uv - e.xy).xyz),
                length(texture(iChannel3, uv + e.yx).xyz) - length(texture(iChannel3, uv - e.yx).xyz));
    return grad;
}

void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
    vec2 random_v = get_random_v(VORONOI_UV_SCALE*fragCoord/iResolution.xy); //texture(iChannel2,0.1*fragCoord/iResolution.xy).xy-vec2(0.5);

    if (1 == 0) {
        fragColor = vec4(random_v,1.,1.);
    }
    else {
    
    // TRAIT: -1. * 
    vec2 cam_grad = camGradient(fragCoord);

    // advection step
    vec2 v = getAdvectedV(fragCoord);
    
    float d = getDivergence(fragCoord);
    
    //v = v * (1. + length(cam_grad));

    vec2 perturb = clamp(get_mouse_perturbation(fragCoord), -1.,1.);
    
    // TRAIT: oscillate?
    //v = v + perturb + clamp(sin(2.*iTime),0.,1.) * cam_grad;
    
    v = v + perturb + 0.5 * cam_grad;
    
    v = bound(v);
    
    fragColor = vec4(v,0.,1.);
    }
}`;
const external_code_B = `/*
Mouse tracking / interactivity
*/




void mainImage( out vec4 fragColor, in vec2 fragCoord )
{    
    vec4 m2_mouse  = texelFetch(iChannel1, M2_POS_ADDR, 0);
    vec4 m1_mouse  = texelFetch(iChannel1, M1_POS_ADDR, 0);
    vec4 m0_mouse  = texelFetch(iChannel1, M0_POS_ADDR, 0);

    
    bool draw = (iMouse.z > 0.) && (m2_mouse.z > 0.) && (m1_mouse.z > 0.);

    if (ivec2(fragCoord) == M2_POS_ADDR) {
        //vec2 prevMouse = texelFetch(iChannel1, MOUSE_POS_ADDR, 0).xy;
        fragColor = vec4(iMouse.xyz, 0.);
    }
    
    if (ivec2(fragCoord) == M1_POS_ADDR) {
        fragColor = m2_mouse;
    }
    
    if (ivec2(fragCoord) == M0_POS_ADDR) {
        fragColor = m1_mouse;
    }

    
    if (ivec2(fragCoord) == DRAW_ADDR) {
        fragColor = draw ? vec4(1.) : vec4(0.);
    }
}`;
const external_code_C = `


vec2 get_mouse_perturbation(in vec2 fragCoord) {
    // read mouse variables
    bool draw      = texelFetch(iChannel1, DRAW_ADDR, 0).x > 0.;
    vec2 m2 = texelFetch(iChannel1, M2_POS_ADDR, 0).xy;
    vec2 m1 = texelFetch(iChannel1, M1_POS_ADDR, 0).xy;
    vec2 m0 = texelFetch(iChannel1, M0_POS_ADDR, 0).xy;

    return get_mouse_perturbation_calcuation(fragCoord, draw, m2, m1, m0);
}

float getDivergence(in vec2 fragCoord) {
    
    // sample the velocities around this point
    vec2 va = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vb = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vc = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2(-1, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vd = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 ve = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vf = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 0, 1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vg = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1,-1)) % ivec2(iResolution.xy), 0).xy;
    vec2 vh = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 0)) % ivec2(iResolution.xy), 0).xy;
    vec2 vi = texelFetch(iChannel0, (ivec2(fragCoord) + ivec2( 1, 1)) % ivec2(iResolution.xy), 0).xy;

    return divergence_calculation(va,vb,vc,vd,ve,vf,vg,vh,vi);
    
    //return (va+vb+vc+vd+ve+vf+vg+vh+vi)/9.;
}

vec2 get_v(in vec2 fragCoord) {
    return texture(iChannel0, fragCoord / iResolution.xy).xy;
}

float shade(vec2 fragCoord) {
    float a = length(get_v(fragCoord+ vec2(1,0))); //voronoi_f1_colors( 10.* (fragCoord + vec2(0,1)) / iResolution.xy, 1.0, 2.0, 3.14159/4.).w;
    float b = length(get_v(fragCoord + vec2(-1,0)));//voronoi_f1_colors( 10.* (fragCoord + vec2(0,-1)) / iResolution.xy, 1.0, 2.0, 3.14159/4.).w;
    float c = length(get_v(fragCoord + vec2(0,1)));//voronoi_f1_colors( 10.* (fragCoord + vec2(1,0)) / iResolution.xy, 1.0, 2.0, 3.14159/4.).w;
    float d = length(get_v(fragCoord + vec2(0,-1)));//voronoi_f1_colors( 10.* (fragCoord + vec2(-1,0)) / iResolution.xy, 1.0, 2.0, 3.14159/4.).w;
    vec2 grad = normalize(vec2((a-b)/2., (c-d)/2.));
    vec2 light = vec2(cos(iTime),sin(iTime));
    return 0.5 + 0.5 *dot(grad,light);
    //return 5.*a;
}


// from https://www.shadertoy.com/view/MsjXRt
// todo: my own implementation
vec3 HueShift (in vec3 Color, in float Shift)
{
    vec3 P = vec3(0.55735)*dot(vec3(0.55735),Color);
    
    vec3 U = Color-P;
    
    vec3 V = cross(vec3(0.55735),U);    

    Color = U*cos(Shift*6.2832) + V*sin(Shift*6.2832) + P;
    
    return Color;
}


void mainImage( out vec4 fragColor, in vec2 fragCoord )
{
    vec2 uv = fragCoord / iResolution.xy;

    // sample flow map
    vec2 flow = texture(iChannel0, (fragCoord)/iResolution.xy).xy;
    
    // get some vector quantities
    float d = getDivergence(fragCoord);
    float divergence = clamp(-d, 0.,1.);
    float convergence = clamp(d, 0., 1.);

    // use the flowmap to offset sampling into the previous frame
    vec4 prev = texture(iChannel2, vec2(fragCoord - flow) / iResolution.xy);
    
    // TRAITS: 0.99, 0.999
    prev*=0.99;
    
    //vec4 colors =  voronoi_f1_colors( VORONOI_UV_SCALE * fragCoord / iResolution.xy, VORONOI_RANDOMNESS, VORONOI_EXPONENT, VORONOI_ANGLE);
    
    // TRAIT: 1.- is a trait
    vec4 colors = texture(iChannel3, fragCoord / iResolution.xy);

    vec3 result = clamp(0.15*divergence * colors.xyz + (1.-0.15*divergence) * prev.xyz, 0., 1.);
    
    float mouse_movement = length(get_mouse_perturbation(fragCoord));
    
    //result = HueShift(result, length(result)*30.);
    
    result = (1.+0.01*length(flow))*HueShift(clamp(result,0.,1.), 0.005*length(flow));

    //vec3 result = shade(fragCoord) * mix(prev.xyz, colors.xyz, divergence);
    fragColor = vec4(result,colors.w);// vec4(divergence,divergence,divergence,1.);
    //}
}`;

class ImportError extends Error {}

// Some of this code is based off of: https://codepen.io/jbltx/pen/eYZwEja

const app = {
    mode: null, /* capture or animate */
    status : null, /* null or 'ready' */
    capture: null, /* base64 capture */
    render: null, /* capture or animation callback */
    canvas: null,
    gl: null,

    mouseX: 0,
    mouseY: 0,
    mouseZ: 0,
    
    program: null,

    vertexArray: null,

    bufferAProgram: null,
    bufferBProgram: null,
    bufferCProgram: null,

    framebufferA : null,
    framebufferB : null,
    framebufferC : null,

    textureA: null,
    textureB: null,
    textureC: null
};

function resizeCanvasToWindow() {
    const canvas = app.canvas;
    canvas.width = window.innerWidth;
    canvas.height = window.innerHeight;
}

function click_setMouseXY(e) {
    const canvas = app.canvas;
    const rect = canvas.getBoundingClientRect();
    app.mouseX = e.clientX - rect.left;
    app.mouseY = rect.height - (e.clientY - rect.top) - 1;  // bottom is 0 in WebGL
}

function touch_setMouseXY(e) {
  e.preventDefault();
  const canvas = app.canvas;
  const rect = canvas.getBoundingClientRect();
  
  // i'm reading that on android mobile the property is changedTouches
  let touch = null;
  if (e.touches) {
    touch = e.touches[0]
  }
  else if (e.changedTouches) {
    touch = e.changedTouches[0]
  }

  app.mouseX = touch.pageX - rect.left;
  app.mouseY = rect.height - (touch.pageY - rect.top) - 1;  // bottom is 0 in WebGL
}

function handle_mousedown(e) {
  e.preventDefault();
  app.mouseZ = 1.0;
}

function handle_mouseup(e) {
  e.preventDefault();
  app.mouseZ = 0.0;
}

function handle_touchstart(e) {
  e.preventDefault();
  app.mouseZ = 1.0;
}

function handle_touchend(e) {
  e.preventDefault();
  app.mouseZ = 0.0;
}

// create a canvas element the size of the screen, that also automatically resizes and updates mouse positions
function createCanvasIfNotExists() {

    // lazy create the canvas
    if (!app.canvas) {
        const canvas = document.createElement('canvas')
        canvas.setAttribute("id", "canvas")
        document.body.appendChild(canvas)
        app.canvas = canvas;
    }

    // size the canvas to the entire window
    resizeCanvasToWindow();

    window.addEventListener('resize', resizeCanvasToWindow);

    // touchmove (tablets/phones) or mousemove...
    app.canvas.addEventListener('mousemove', click_setMouseXY);
    app.canvas.addEventListener('touchmove', touch_setMouseXY);

    // touchstart/end (tablets/phones) or mouseup/down
    app.canvas.addEventListener('mousedown', handle_mousedown);
    app.canvas.addEventListener('mouseup', handle_mouseup);
    app.canvas.addEventListener('touchstart', handle_touchstart);
    app.canvas.addEventListener('touchend', handle_touchend);
}

function createWebGLContextIfNotExists() {
    // lazy load the web gl context
    if (!app.gl) {
        app.gl = app.canvas.getContext("webgl2");
    }
}

function configureVertexArray() {
  const gl = app.gl;
  app.vertexArray = gl.createVertexArray();
  gl.bindVertexArray(app.vertexArray);
  gl.bindVertexArray(null);
}

function init() {

    createCanvasIfNotExists();
    createWebGLContextIfNotExists();

    const gl = app.gl;

    // make the buffers
    app.bufferAProgram = createShaderProgram(getCommonShaderCode() + getBufferFragmentShaderCode("A"));
    app.bufferBProgram = createShaderProgram(getCommonShaderCode() + getBufferFragmentShaderCode("B"));
    app.bufferCProgram = createShaderProgram(getCommonShaderCode() + getBufferFragmentShaderCode("C"));
    app.program        = createShaderProgram(getCommonShaderCode() + getFragmentShaderCode());  
    
    // make the frame buffers (???)
    app.framebufferA = gl.createFramebuffer();
    app.framebufferB = gl.createFramebuffer();    
    app.framebufferC = gl.createFramebuffer();   
    
    // make the textures
    app.textureA = createTexture(gl, gl.canvas.width, gl.canvas.height);   
    app.textureB = createTexture(gl, gl.canvas.width, gl.canvas.height); 
    app.textureC = createTexture(gl, gl.canvas.width, gl.canvas.height);      

    // do a bunch of other stuff
    configureWebGLContext();

    app.status = "ready";
}

function createShaderProgram(fragmentShaderCode) {
  
  const gl = app.gl;
  const vertexShader = createShader(getVertexShaderCode(), gl.VERTEX_SHADER);
  const fragmentShader = createShader(fragmentShaderCode, gl.FRAGMENT_SHADER);

  const program = gl.createProgram();
  gl.attachShader(program, vertexShader);
  gl.attachShader(program, fragmentShader);
  gl.linkProgram(program);
  var success = gl.getProgramParameter(program, gl.LINK_STATUS);
  if (!success) {
      throw ("program filed to link:" + gl.getProgramInfoLog (program));
  }    
  return program;
}

function createShader(shaderCode, shaderType) {
  
  const gl = app.gl;

  var shader = gl.createShader(shaderType);
  gl.shaderSource(shader, shaderCode);
  gl.compileShader(shader);

  var message = gl.getShaderInfoLog(shader);
  if (message.length > 0) {
    /* message may be an error or a warning */
    //throw message; 
    throw "could not compile shader:" + gl.getShaderInfoLog(shader);
  }

  return shader;
}

function createTexture(w, h) 
{
    const gl = app.gl;
    const texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, w, h, 
                                   0, gl.RGBA, gl.UNSIGNED_BYTE, null);
                                   gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.bindTexture(gl.TEXTURE_2D, null);
    return texture;
}

// TODO: create frame rendering API

function configureWebGLContext() {
    
    const gl = app.gl;    

    const program = app.program;

    // look up where the vertex data needs to go.
    const positionAttributeLocation = gl.getAttribLocation(program, "position");

    // look up uniform locations
    const resolutionLocation = gl.getUniformLocation(program, "iResolution");
    const mouseLocation      = gl.getUniformLocation(program, "iMouse");
    const timeLocation       = gl.getUniformLocation(program, "iTime");

    // Create a buffer to put three 2d clip space points in
    const positionBuffer = gl.createBuffer();

    // Bind it to ARRAY_BUFFER (think of it as ARRAY_BUFFER = positionBuffer)
    gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);

    // fill it with a 2 triangles that cover clipspace
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
    -1, -1,  // first triangle
     1, -1,
    -1,  1,
    -1,  1,  // second triangle
     1, -1,
     1,  1,
    ]), gl.STATIC_DRAW);

    let then = 0;
    let time = 0;
    
    function render(now) {

      let gl = app.gl;

      if (app.mode == "animate") {
        now *= 0.001;  // convert to seconds
        const elapsedTime = Math.min(now - then, 0.1);
        time += elapsedTime;
        then = now;
      }
      else if (app.mode == "capture") {
        time = now;
      }

      drawBuffer(app.bufferAProgram, time, frame);
      drawBuffer(app.bufferBProgram, time, frame);
      drawBuffer(app.bufferCProgram, time, frame);
  
      // Tell WebGL how to convert from clip space to pixels
      gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
  
      // Tell it to use our program (pair of shaders)
      gl.useProgram(program);
  
      // Turn on the attribute
      gl.enableVertexAttribArray(positionAttributeLocation);
  
      // Bind the position buffer.
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
  
      // Tell the attribute how to get data out of positionBuffer (ARRAY_BUFFER)
      gl.vertexAttribPointer(
          positionAttributeLocation,
          2,          // 2 components per iteration
          gl.FLOAT,   // the data is 32bit floats
          false,      // don't normalize the data
          0,          // 0 = move forward size * sizeof(type) each iteration to get the next position
          0,          // start at the beginning of the buffer
      );
  
      gl.uniform2f(resolutionLocation, gl.canvas.width, gl.canvas.height);
      gl.uniform2f(mouseLocation, app.mouseX, app.mouseY);
      gl.uniform1f(timeLocation, time);
  
      gl.drawArrays(
          gl.TRIANGLES,
          0,     // offset
          6,     // num vertices to process
      );

      if (app.mode == "capture") {
        // TODO: proper DPI tricks if DPI != 96 desired.
        app.capture = app.canvas.toDataURL('image/png', 1).substring(22);
      }
      else if (app.mode == "animate") {
         requestAnimationFrame(app.render);
      }

    }

    app.render = render;
}

function drawBuffer(program, time, frame) {

    const gl = app.gl;

    gl.bindFramebuffer(gl.FRAMEBUFFER, null);

    // TODO: remove these lines? 
    gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
    //gl.clearColor(0, 0, 0, 0);
    //gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

    gl.useProgram(program);

    gl.uniform1f(gl.getUniformLocation(program, "iTime"), time);
    gl.uniform1i(gl.getUniformLocation(app.bufferAProgram, "iFrame"), frame);
    gl.uniform3f(gl.getUniformLocation(program, "iMouse"), app.mouseX, app.mouseY, app.mouseZ);
    gl.uniform3f(gl.getUniformLocation(program, "iResolution"), gl.canvas.width, gl.canvas.height, 1.0);
    
    // bind channel 0
    gl.activeTexture(gl.TEXTURE0);
    gl.bindTexture(gl.TEXTURE_2D, app.textureA);
    gl.uniform1i(gl.getUniformLocation(program, "iChannel0"), 0);

    // bind channel 1
    gl.activeTexture(gl.TEXTURE1);
    gl.bindTexture(gl.TEXTURE_2D, app.textureB);
    gl.uniform1i(gl.getUniformLocation(program, "iChannel1"), 1);
  
    // bind channel 2
    gl.activeTexture(gl.TEXTURE2);
    gl.bindTexture(gl.TEXTURE_2D, app.textureC);
    gl.uniform1i(gl.getUniformLocation(program, "iChannel2"), 2);

    gl.bindVertexArray(app.vertexArray);

    gl.drawArrays(gl.TRIANGLES, 0, 6);
}


function getVertexShaderCode() {
    const vs = `#version 300 es

    // an attribute will receive data from a buffer
    in vec4 position;

    // all shaders have a main function
    void main() {

      // gl_Position is a special variable a vertex shader
      // is responsible for setting
      gl_Position = position;
    }`;
    return vs;
}


function getCommonShaderCode() {

  const fs = `#version 300 es

    precision mediump float;
`

    +

    common_code;

  return fs;
}


function getBufferFragmentShaderCode(buffer) {

  const buffer_code = ({ "A": external_code_A, "B": external_code_B, "C": external_code_C })[buffer];

  const fs = `
    out vec4 myOutputColor;

    uniform sampler2D iChannel0;
    uniform sampler2D iChannel1;
    uniform sampler2D iChannel2;
    uniform sampler2D iChannel3;

    uniform vec2 iResolution;
    uniform vec2 iMouse;
    uniform float iTime;`

    

    +

    buffer_code

    +

    `
    
    void main() {
      mainImage(myOutputColor, gl_FragCoord.xy);
    }
  `;

  return fs;

}

function getFragmentShaderCode() {
  // build the fragment shader by prepending / postpending other code
  const fs = `
    out vec4 myOutputColor;

    uniform sampler2D iChannel0;
    uniform sampler2D iChannel1;
    uniform sampler2D iChannel2; 
    uniform sampler2D iChannel3;    

    uniform vec2 iResolution;
    uniform vec2 iMouse;
    uniform float iTime;`

    

    +

    external_code

    +

    `
    
    void main() {
      mainImage(myOutputColor, gl_FragCoord.xy);
    }
  `;

  return fs;

}

function capture(time, x, y) {
    app.canvas.width = x;
    app.canvas.height = y;
    app.mode = "capture";
    app.render(time);
}

function animate() {
    resizeCanvasToWindow();
    app.mode = "animate";
    requestAnimationFrame(app.render);
}

function stop() {
    app.mode = "capture";
}


init();
animate();
</script>
</html>